# ▼▼▼ Automatically generated by Terra-Crust, PLEASE DON'T EDIT MANUALLY, Please edit {main template/ sub-module variables} if changes are needed :slight_smile: ▼▼▼
locals {
  cert-manager = {
    atomic                = coalesce(var.cert-manager.atomic, true)
    cleanup_on_fail       = coalesce(var.cert-manager.cleanup_on_fail, true)
    create_namespace      = coalesce(var.cert-manager.create_namespace, true)
    docker_image          = coalesce(var.cert-manager.docker_image, "quay.io/jetstack/cert-manager-controller")
    docker_image_acme     = coalesce(var.cert-manager.docker_image_acme, "quay.io/jetstack/cert-manager-acmesolver")
    docker_image_injector = coalesce(var.cert-manager.docker_image_injector, "quay.io/jetstack/cert-manager-cainjector")
    docker_image_startup  = coalesce(var.cert-manager.docker_image_startup, "quay.io/jetstack/cert-manager-startupapicheck")
    docker_image_webhook  = coalesce(var.cert-manager.docker_image_webhook, "quay.io/jetstack/cert-manager-webhook")
    docker_pull_policy    = coalesce(var.cert-manager.docker_pull_policy, "IfNotPresent")
    helm_chart_name       = coalesce(var.cert-manager.helm_chart_name, "cert-manager")
    helm_chart_version    = coalesce(var.cert-manager.helm_chart_version, "1.15.1")
    helm_release_name     = coalesce(var.cert-manager.helm_release_name, "cert-manager")
    helm_repo_url         = coalesce(var.cert-manager.helm_repo_url, "https://charts.jetstack.io")
    namespace             = coalesce(var.cert-manager.namespace, "kube-system")
    timeout               = coalesce(var.cert-manager.timeout, 300)
    wait                  = coalesce(var.cert-manager.wait, true)


  }
  kafka = {
    bootstrap_node_port = coalesce(var.kafka.bootstrap_node_port, 32300)
    brokers             = coalesce(var.kafka.brokers, 3)
    kafka_version       = coalesce(var.kafka.kafka_version, "3.6.0")
    root_log_level      = coalesce(var.kafka.root_log_level, "INFO")


    kafka_config = var.kafka.kafka_config != null ? merge(var.kafka.kafka_config,
      tomap({
        "auto.create.topics.enable"                           = contains(keys(var.kafka.kafka_config), "auto.create.topics.enable") != false ? var.kafka.kafka_config["auto.create.topics.enable"] : "false"
        "auto.leader.rebalance.enable"                        = contains(keys(var.kafka.kafka_config), "auto.leader.rebalance.enable") != false ? var.kafka.kafka_config["auto.leader.rebalance.enable"] : "false"
        "client.quota.callback.class"                         = contains(keys(var.kafka.kafka_config), "client.quota.callback.class") != false ? var.kafka.kafka_config["client.quota.callback.class"] : "io.strimzi.kafka.quotas.StaticQuotaCallback"
        "client.quota.callback.static.storage.check-interval" = contains(keys(var.kafka.kafka_config), "client.quota.callback.static.storage.check-interval") != false ? var.kafka.kafka_config["client.quota.callback.static.storage.check-interval"] : "600"
        "controlled.shutdown.enable"                          = contains(keys(var.kafka.kafka_config), "controlled.shutdown.enable") != false ? var.kafka.kafka_config["controlled.shutdown.enable"] : "true"
        "default.replication.factor"                          = contains(keys(var.kafka.kafka_config), "default.replication.factor") != false ? var.kafka.kafka_config["default.replication.factor"] : "3"
        "delete.topic.enable"                                 = contains(keys(var.kafka.kafka_config), "delete.topic.enable") != false ? var.kafka.kafka_config["delete.topic.enable"] : "true"
        "group.initial.rebalance.delay.ms"                    = contains(keys(var.kafka.kafka_config), "group.initial.rebalance.delay.ms") != false ? var.kafka.kafka_config["group.initial.rebalance.delay.ms"] : "6000"
        "log.flush.scheduler.interval.ms"                     = contains(keys(var.kafka.kafka_config), "log.flush.scheduler.interval.ms") != false ? var.kafka.kafka_config["log.flush.scheduler.interval.ms"] : "2000"
        "log.retention.hours"                                 = contains(keys(var.kafka.kafka_config), "log.retention.hours") != false ? var.kafka.kafka_config["log.retention.hours"] : "24"
        "message.timestamp.type"                              = contains(keys(var.kafka.kafka_config), "message.timestamp.type") != false ? var.kafka.kafka_config["message.timestamp.type"] : "LogAppendTime"
        "min.insync.replicas"                                 = contains(keys(var.kafka.kafka_config), "min.insync.replicas") != false ? var.kafka.kafka_config["min.insync.replicas"] : "1"
        "num.network.threads"                                 = contains(keys(var.kafka.kafka_config), "num.network.threads") != false ? var.kafka.kafka_config["num.network.threads"] : "4"
        "num.recovery.threads.per.data.dir"                   = contains(keys(var.kafka.kafka_config), "num.recovery.threads.per.data.dir") != false ? var.kafka.kafka_config["num.recovery.threads.per.data.dir"] : "2"
        "num.replica.fetchers"                                = contains(keys(var.kafka.kafka_config), "num.replica.fetchers") != false ? var.kafka.kafka_config["num.replica.fetchers"] : "4"
        "offsets.topic.replication.factor"                    = contains(keys(var.kafka.kafka_config), "offsets.topic.replication.factor") != false ? var.kafka.kafka_config["offsets.topic.replication.factor"] : "3"
        "replica.selector.class"                              = contains(keys(var.kafka.kafka_config), "replica.selector.class") != false ? var.kafka.kafka_config["replica.selector.class"] : "org.apache.kafka.common.replica.RackAwareReplicaSelector"
        "socket.receive.buffer.bytes"                         = contains(keys(var.kafka.kafka_config), "socket.receive.buffer.bytes") != false ? var.kafka.kafka_config["socket.receive.buffer.bytes"] : "1048576"
        "socket.request.max.bytes"                            = contains(keys(var.kafka.kafka_config), "socket.request.max.bytes") != false ? var.kafka.kafka_config["socket.request.max.bytes"] : "104857600"
        "socket.send.buffer.bytes"                            = contains(keys(var.kafka.kafka_config), "socket.send.buffer.bytes") != false ? var.kafka.kafka_config["socket.send.buffer.bytes"] : "1048576"
        "transaction.state.log.min.isr"                       = contains(keys(var.kafka.kafka_config), "transaction.state.log.min.isr") != false ? var.kafka.kafka_config["transaction.state.log.min.isr"] : "1"
        "transaction.state.log.replication.factor" = contains(keys(var.kafka.kafka_config), "transaction.state.log.replication.factor") != false ? var.kafka.kafka_config["transaction.state.log.replication.factor"] : "3" }
      )) : {
      "auto.create.topics.enable"                           = "false"
      "auto.leader.rebalance.enable"                        = "false"
      "client.quota.callback.class"                         = "io.strimzi.kafka.quotas.StaticQuotaCallback"
      "client.quota.callback.static.storage.check-interval" = "600"
      "controlled.shutdown.enable"                          = "true"
      "default.replication.factor"                          = "3"
      "delete.topic.enable"                                 = "true"
      "group.initial.rebalance.delay.ms"                    = "6000"
      "log.flush.scheduler.interval.ms"                     = "2000"
      "log.retention.hours"                                 = "24"
      "message.timestamp.type"                              = "LogAppendTime"
      "min.insync.replicas"                                 = "1"
      "num.network.threads"                                 = "4"
      "num.recovery.threads.per.data.dir"                   = "2"
      "num.replica.fetchers"                                = "4"
      "offsets.topic.replication.factor"                    = "3"
      "replica.selector.class"                              = "org.apache.kafka.common.replica.RackAwareReplicaSelector"
      "socket.receive.buffer.bytes"                         = "1048576"
      "socket.request.max.bytes"                            = "104857600"
      "socket.send.buffer.bytes"                            = "1048576"
      "transaction.state.log.min.isr"                       = "1"
      "transaction.state.log.replication.factor"            = "3"
    }

    listener_tls = var.kafka.listener_tls != null ? merge(var.kafka.listener_tls,
      tomap({
        "external_tls_enabled" = contains(keys(var.kafka.listener_tls), "external_tls_enabled") != false ? var.kafka.listener_tls["external_tls_enabled"] : "true"
        "internal_tls_enabled" = contains(keys(var.kafka.listener_tls), "internal_tls_enabled") != false ? var.kafka.listener_tls["internal_tls_enabled"] : "true" }
      )) : {
      "external_tls_enabled" = "true"
      "internal_tls_enabled" = "true"
    }

    pod_annotations = var.kafka.pod_annotations != null ? merge(var.kafka.pod_annotations,
      tomap({
        "karpenter.sh/do-not-disrupt" = contains(keys(var.kafka.pod_annotations), "karpenter.sh/do-not-disrupt") != false ? var.kafka.pod_annotations["karpenter.sh/do-not-disrupt"] : "true" }
      )) : {
      "karpenter.sh/do-not-disrupt" = "true"
    }

    ports = var.kafka.ports != null ? merge(var.kafka.ports,
      tomap({
        "external_port" = contains(keys(var.kafka.ports), "external_port") != false ? var.kafka.ports["external_port"] : 9094
        "internal_port" = contains(keys(var.kafka.ports), "internal_port") != false ? var.kafka.ports["internal_port"] : 9092 }
      )) : {
      "external_port" = 9094
      "internal_port" = 9092
    }

    service_annotations = var.kafka.service_annotations != null ? merge(var.kafka.service_annotations,
      tomap({
        "consul.hashicorp.com/service-sync" = contains(keys(var.kafka.service_annotations), "consul.hashicorp.com/service-sync") != false ? var.kafka.service_annotations["consul.hashicorp.com/service-sync"] : "true" }
      )) : {
      "consul.hashicorp.com/service-sync" = "true"
    }

  }
  nifi-cluster = {
    atomic             = coalesce(var.nifi-cluster.atomic, true)
    cleanup_on_fail    = coalesce(var.nifi-cluster.cleanup_on_fail, true)
    cluster_name       = coalesce(var.nifi-cluster.cluster_name, "nifi-cluster")
    create_namespace   = coalesce(var.nifi-cluster.create_namespace, true)
    dns_suffix         = coalesce(var.nifi-cluster.dns_suffix, "local")
    docker_image       = coalesce(var.nifi-cluster.docker_image, "apache/nifi")
    docker_pull_policy = coalesce(var.nifi-cluster.docker_pull_policy, "IfNotPresent")
    helm_chart_name    = coalesce(var.nifi-cluster.helm_chart_name, "nifi-cluster")
    helm_chart_version = coalesce(var.nifi-cluster.helm_chart_version, "1.9.0")
    helm_release_name  = coalesce(var.nifi-cluster.helm_release_name, "nifi-cluster")
    helm_repo_url      = coalesce(var.nifi-cluster.helm_repo_url, "oci://ghcr.io/konpyutaika/helm-charts/")
    namespace          = coalesce(var.nifi-cluster.namespace, "nifi")
    timeout            = coalesce(var.nifi-cluster.timeout, 300)
    wait               = coalesce(var.nifi-cluster.wait, true)


  }
  nifi-kop = {
    atomic             = coalesce(var.nifi-kop.atomic, true)
    bootstrap_issuers  = coalesce(var.nifi-kop.bootstrap_issuers, true)
    cleanup_on_fail    = coalesce(var.nifi-kop.cleanup_on_fail, true)
    create_namespace   = coalesce(var.nifi-kop.create_namespace, true)
    docker_image       = coalesce(var.nifi-kop.docker_image, "ghcr.io/konpyutaika/docker-images/nifikop")
    docker_pull_policy = coalesce(var.nifi-kop.docker_pull_policy, "IfNotPresent")
    helm_chart_name    = coalesce(var.nifi-kop.helm_chart_name, "nifikop")
    helm_chart_version = coalesce(var.nifi-kop.helm_chart_version, "1.9.0")
    helm_release_name  = coalesce(var.nifi-kop.helm_release_name, "nifikop")
    helm_repo_url      = coalesce(var.nifi-kop.helm_repo_url, "oci://ghcr.io/konpyutaika/helm-charts/")
    namespace          = coalesce(var.nifi-kop.namespace, "nifi")
    timeout            = coalesce(var.nifi-kop.timeout, 300)
    wait               = coalesce(var.nifi-kop.wait, true)


  }
  palworld = {
    atomic             = coalesce(var.palworld.atomic, true)
    cleanup_on_fail    = coalesce(var.palworld.cleanup_on_fail, true)
    create_namespace   = coalesce(var.palworld.create_namespace, true)
    helm_chart_name    = coalesce(var.palworld.helm_chart_name, "palworld")
    helm_chart_version = coalesce(var.palworld.helm_chart_version, "0.2.2")
    helm_release_name  = coalesce(var.palworld.helm_release_name, "palworld")
    helm_repo_url      = coalesce(var.palworld.helm_repo_url, "https://caleb-devops.github.io/helm-charts")
    namespace          = coalesce(var.palworld.namespace, "tailscale")
    timeout            = coalesce(var.palworld.timeout, 300)
    wait               = coalesce(var.palworld.wait, true)


  }
  strimzi_operator = {
    atomic              = coalesce(var.strimzi_operator.atomic, true)
    cleanup_on_fail     = coalesce(var.strimzi_operator.cleanup_on_fail, true)
    create_namespace    = coalesce(var.strimzi_operator.create_namespace, true)
    docker_registry     = coalesce(var.strimzi_operator.docker_registry, "packages.af-eng.io/docker")
    feature_gates       = coalesce(var.strimzi_operator.feature_gates, "-")
    helm_chart_name     = coalesce(var.strimzi_operator.helm_chart_name, "strimzi-kafka-operator")
    helm_chart_version  = coalesce(var.strimzi_operator.helm_chart_version, "0.41.0")
    helm_release_name   = coalesce(var.strimzi_operator.helm_release_name, "strimzi-kafka-operator")
    helm_repo_url       = coalesce(var.strimzi_operator.helm_repo_url, "oci://quay.io/strimzi-helm/")
    log_level           = coalesce(var.strimzi_operator.log_level, "info")
    namespace           = coalesce(var.strimzi_operator.namespace, "strimzi-operator")
    replicas            = coalesce(var.strimzi_operator.replicas, 3)
    timeout             = coalesce(var.strimzi_operator.timeout, 300)
    wait                = coalesce(var.strimzi_operator.wait, true)
    watch_any_namespace = coalesce(var.strimzi_operator.watch_any_namespace, true)


  }
  tailscale = {
    atomic             = coalesce(var.tailscale.atomic, true)
    cleanup_on_fail    = coalesce(var.tailscale.cleanup_on_fail, true)
    create_namespace   = coalesce(var.tailscale.create_namespace, true)
    helm_chart_name    = coalesce(var.tailscale.helm_chart_name, "tailscale-operator")
    helm_chart_version = coalesce(var.tailscale.helm_chart_version, "1.68.1")
    helm_release_name  = coalesce(var.tailscale.helm_release_name, "tailscale-operator")
    helm_repo_url      = coalesce(var.tailscale.helm_repo_url, "https://pkgs.tailscale.com/helmcharts")
    namespace          = coalesce(var.tailscale.namespace, "tailscale")
    timeout            = coalesce(var.tailscale.timeout, 300)
    wait               = coalesce(var.tailscale.wait, true)


  }
}




